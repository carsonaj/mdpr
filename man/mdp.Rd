% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mdp_wrapper.R
\name{mdp}
\alias{mdp}
\title{Policy minimizer for Markov decision processes}
\usage{
mdp(states, actions, trans_probs, costs, horizon)
}
\arguments{
\item{states}{- vector of states}

\item{actions}{- function, input: state,}

\item{trans_probs}{- function, input: current state, action taken, next state,}

\item{costs}{- function, input: time, current state, action taken, next state,}

\item{horizon}{- positive integer}
}
\value{
policy - function, input: time, current state,
}
\description{
Policy minimizer for Markov decision processes
}
